import umapimport pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as snsfrom lifelines.statistics import logrank_testfrom sklearn.ensemble import RandomForestClassifierfrom sklearn.model_selection import train_test_splitimport vennfrom sklearn.preprocessing import StandardScalerfrom scipy import statsimport qnormcolor_palette=["darkcyan", "blue", "crimson", "orange", "yellow", "saddlebrown", "turquoise"]def gmt_to_binary(gmt,genelist):    lines=gmt.readlines()    pathway= pd.DataFrame(columns=range(0,len(lines)+1),index=range(0,len(genelist)))    pathway=pathway.fillna(0)    pathway.iloc[:,0]=genelist.iloc[:,1]    pathway_name=[]    for num,write in enumerate(lines):        write = write.split("\t")        temp=pd.DataFrame(data=write)        pathway_name.append(temp.iloc[0,0])        pathway.iloc[:,num+1][pathway.iloc[:,0].isin(temp.iloc[:,0])]=1    gmt.close()    pathway=pathway.iloc[:,1:]    pathway.columns=pathway_name        return pathwaydef venn_rank(tensor,gmt,ranks,genelist,sample_info,threshold):    if ranks==0:        venn_rank_un(tensor,gmt,genelist,sample_info,threshold)    else:        venn_rank_su(tensor,gmt,ranks,genelist,sample_info,threshold)    #sample_tensor_selec=sample_tensor.iloc[:,ranks.iloc[:,0]]    #omics_tensor_selec=omics_tensor.iloc[:,ranks.iloc[:,0]]    #gene_tensor_selec=gene_tensor.iloc[:,ranks.iloc[:,0]]    def venn_rank_un(tensor,gmt,genelist,sample_info,threshold):    a=set()    b=set()    c=set()    d=set()    e=set()    f=set()    gmt_binary=gmt_to_binary(gmt,genelist)    #ranks=ranks.drop_duplicates(ranks.columns[0],'first')    omics_tensor = pd.DataFrame(data=tensor[0])    gene_tensor =pd.DataFrame(data=tensor[1])    groups=[]    sample_tensor =pd.DataFrame(data=tensor[2])    sample_tensor_selec=sample_tensor.iloc[:,:]    gomics_tensor_selec=omics_tensor.iloc[:,:]    gene_tensor_selec=gene_tensor.iloc[:,:]    ### normalization gene matirx    scal = StandardScaler()    gene_tensor_norm = StandardScaler().fit(gene_tensor_selec).transform(gene_tensor_selec)    gene_tensor_norm =pd.DataFrame(data=gene_tensor_norm)    minvalue=0    for  num,i in enumerate(gene_tensor_norm.iloc[0,:]):        if min(gene_tensor_norm.iloc[:,num])< minvalue :            minvalue=min(gene_tensor_norm.iloc[:,num])    gene_tensor_norm+=(abs(minvalue)+0.00000000000000001)    point = pd.DataFrame(index=range(0,len(sample_tensor.iloc[:,0])), columns=range(0,len(sample_tensor_selec.iloc[0,:])))    point=point.fillna(0)    point.columns = sample_tensor_selec.columns    sample_tensor_selec=qnorm.quantile_normalize(sample_tensor_selec, axis=1, ncpus=8)    sample_tensor_norm=pd.DataFrame(data=sample_tensor_selec)    for numb,i in enumerate(sample_tensor_norm.index):        estimator=stats.gaussian_kde(sample_tensor_norm.iloc[i,:], bw_method='silverman')        X=np.array(sample_tensor_norm.iloc[i,:])        C = [estimator.integrate_box_1d(-np.Inf,x) for x in X]        for tttt,t in enumerate(C):            if t>threshold:                point.iloc[i,tttt]=2    sample_info.columns =['sample','type']    sample_info=sample_info.reset_index(drop=True)    point2=pd.merge(point,sample_info['type'],left_index=True,right_index=True,how='left')        groups=[]    for name, group in point2.groupby('type'):        #groups.append(group)        groups.append(name)    subtype_rank = pd.DataFrame(index=range(0,len(groups)), columns=point2.columns[:-1])    subtype_rank=subtype_rank.fillna(0)    subtype_rank.index=groups    for num,group in enumerate (groups):        point3=point2[point2['type']==group]        for i in point3.columns[:-1]:                if point3[i].sum() >= len(point3)*2*0.5: ####more than 80%                #print(num,i)                subtype_rank.loc[group,i]=1    re_subtype_rank=reverse(subtype_rank)    re_subtype_rank.index=subtype_rank.columns    re_subtype_rank.columns=subtype_rank.index    gmt_pathway=gmt_binary.columns       point4=pd.DataFrame(data=point2)    re_subtype_rank1=pd.DataFrame(data=re_subtype_rank)    #rank1=[]    #rank1=re_subtype_rank[re_subtype_rank.loc[:,group]==1].index.to_list()    if len(groups)==2:        ven=[a,b]    elif len(groups)==3:        ven=[a,b,c]    elif len(groups)==4:        ven=[a,b,c,d]    elif len(groups)==5:        ven=[a,b,c,d,e]    elif len(groups)==6:        ven=[a,b,c,d,e,f]    num=0    for g,(group , name) in enumerate(zip(re_subtype_rank.columns,groups)):        rank1=[]        rank1=re_subtype_rank[re_subtype_rank.loc[:,group]==1].index.to_list()        ven[num]=set(rank1)        num+=1            #return groups        #new['Class'].unique()        #f=new[new['Class']=='CMS1']    labels = venn.get_labels(ven,fill=['number'])    if len(groups)==2:        fig , ax = venn.venn2(labels,names=groups)    elif len(groups)==3:        fig , ax = venn.venn3(labels,names=groups)    elif len(groups)==4:        fig , ax = venn.venn4(labels,names=groups)    elif len(groups)==5:        fig , ax = venn.venn5(labels,names=groups)    elif len(groups)==6:        fig , ax = venn.venn6(labels,names=groups)    return 0def reverse(data):    ndata = data.to_numpy()    ndata = ndata.T    data = pd.DataFrame(data = ndata[:,:])    return datadef venn_unsupervised(tensor,sample_info,gmt_binary,threshold): ##ranksample generater    omics_tensor = pd.DataFrame(data=tensor[0])    gene_tensor =pd.DataFrame(data=tensor[1])    sample_tensor =pd.DataFrame(data=tensor[2])    ranksample = pd.DataFrame(index=range(0,len(gene_tensor.iloc[:,0])), columns=(sample_info.iloc[:,0]))    ranksample=ranksample.fillna(0)    sample_tensor_selec=sample_tensor.iloc[:,:]    gomics_tensor_selec=omics_tensor.iloc[:,:]    gene_tensor_selec=gene_tensor.iloc[:,:]    ### normalization gene matirx    scal = StandardScaler()    gene_tensor_norm = StandardScaler().fit(gene_tensor_selec).transform(gene_tensor_selec)    gene_tensor_norm =pd.DataFrame(data=gene_tensor_norm)    minvalue=0    for  num,i in enumerate(gene_tensor_norm.iloc[0,:]):        if min(gene_tensor_norm.iloc[:,num])< minvalue :            minvalue=min(gene_tensor_norm.iloc[:,num])    gene_tensor_norm+=(abs(minvalue)+0.00000000000000001)    ### rank feature selection using CDF    point = pd.DataFrame(index=range(0,len(sample_tensor.iloc[:,0])), columns=range(0,len(sample_tensor_selec.iloc[0,:])))    point=point.fillna(0)    point.columns = sample_tensor_selec.columns    ### normalization sample matrix    sample_tensor_selec=qnorm.quantile_normalize(sample_tensor_selec, axis=1, ncpus=8)    sample_tensor_norm=pd.DataFrame(data=sample_tensor_selec)    ###selecting feature in sample matrix using CDF    for numb,i in enumerate(sample_tensor_norm.index):        estimator=stats.gaussian_kde(sample_tensor_norm.iloc[i,:], bw_method='silverman')        X=np.array(sample_tensor_norm.iloc[i,:])        C = [estimator.integrate_box_1d(-np.Inf,x) for x in X]        for tttt,t in enumerate(C):            if t>threshold:              point.iloc[i,tttt]=2def labeling(df,sample):    df=df.copy()    i=len(df.iloc[:,0])    sample.index=df.index    sample=sample.iloc[:,1:]    df=pd.merge(df,sample,left_index=True,right_index=True,how='left')    groups=[]    for name, group in df.groupby('type'):        groups.append(name)    num=0    for i in range(len(groups)):        df=df.replace(groups[i],num)        num+=2        H=df.copy()    return H        #re.to_csv('%s/%s_Omics_evidence_v_%d.txt'%(info.outdir,name,info.rank),index=False,sep='\t')def convertJ(df,sample):    df=df.copy()    i=len(df.iloc[:,0])    #df.index= samplename    sample.index=df.index    sample=sample.iloc[:,1:]    df=pd.merge(df,sample,left_index=True,right_index=True,how='left')    groups=[]    for name, group in df.groupby('type'):        groups.append(name)    num=0    for i in range(len(groups)):        df=df.replace(groups[i],num)        num+=2        H=df.copy()    return H                def survival(survival_data,sample_info,score,number):    sample_info.columns=['sample','type']    survival_data.columns=['sample','time','event']    score.index=score.iloc[:,0]    score=score.iloc[:,1:]    score.columns=sample_info['sample']    score=score.fillna(0)    survival_data['groups']=3    pval=pd.DataFrame(index=score.index,columns=['p-value','feature_score'])    for i in range(len(score.index)):        score.columns=sample_info['sample']        survival_data['groups']=3        UP=score.iloc[i,:].sort_values(ascending=False).head(int(len(sample_info['sample'])*number)).index        DOWN=score.iloc[i,:].sort_values(ascending=False).tail(int(len(sample_info['sample'])*number)).index                survival_data.loc[survival_data['sample'].isin(UP),'groups']=1        survival_data.loc[survival_data['sample'].isin(DOWN),'groups']=2        fit=survival_data[survival_data['groups']<3]        fit=fit.reset_index(drop=True)        fit=fit.fillna(0)        labels=['UP','DOWN']        times=fit['time'].to_list()        events=fit['event'].to_list()        groups =fit['groups'].to_list()        E = np.array(events, dtype=np.int32)        T = np.array(times, dtype=np.float32)        ix = np.array(groups) == 2        result = logrank_test(T[ix], T[~ix], E[ix], E[~ix], alpha=.99)        pval.iloc[i,0]=result.p_value    re_score=reverse(score)    re_score.index=score.columns    re_score.columns=score.index    sample_info.index=sample_info['type']    df=pd.merge(re_score,sample_info,left_index=True,right_index=True,how='left')    f=convertJ(re_score,sample_info)    X_train,X_test,y_train,y_test = train_test_split(f.iloc[:,:-1],f['type'],random_state=0)    rf= RandomForestClassifier(n_jobs=-1,random_state=1)    rf.fit(X_train,y_train)    pval['feature_score']=rf.feature_importances_        return pval                def draw_heatmap(mopa,sample_info):    sample_info.columns=['sample','type']    mopa.index=mopa.iloc[:,0]    mopa=mopa.iloc[:,1:]    mopa.columns=sample_info['sample']    mopa=mopa.fillna(0)    re_mopa=reverse(mopa)    re_mopa.index=mopa.columns    re_mopa.columns=mopa.index    f=labeling(re_mopa,sample_info)    re_f=reverse(f)    re_f.columns=f.index    re_f.index=f.columns    re_f=re_f.astype(float)    my_palette = dict(zip(re_f.iloc[-1,:].unique(), ["blue","orange","green","red","yellow"]))    row_colors = re_f.iloc[-1,:].map(my_palette)    plt.figure(figsize=(20,15))    heatmap=sns.clustermap(re_f.iloc[:-1,:], cmap="RdYlBu_r",standard_scale=0,col_colors=row_colors)    return heatmapdef draw_umap(mopa,sample_info):        sample_info.columns=['sample','type']    #mopa.columns=sample_info['sample']    #mopa=mopa.fillna(0)    mopa=mopa.iloc[:,1:]    re_mopa=reverse(mopa)    re_mopa.index=mopa.columns    re_mopa.columns=mopa.index    f=labeling(re_mopa,sample_info)    #reducer = umap.UMAP()    #embedding = reducer.fit_transform(X, y)    #umap = UMAP(random_state=0)    clusterable_embedding = umap.UMAP(n_neighbors=20,min_dist=0.0,n_components=2,random_state=0).fit_transform(f.iloc[:,:len(f.columns)-1])    #umap1, ax = plt.subplots(figsize=(10,10))    plot=pd.DataFrame(index=range(len(clusterable_embedding[:,0])),columns =['x','y','type'])    plot['x']=clusterable_embedding[:,0]    plot['y']=clusterable_embedding[:,1]    plot['type']=sample_info['type'].to_list()    tt=len(sample_info['type'].unique())    if tt==2:      umall=sns.scatterplot(x='x',y='y',hue='type',data=plot,s=90,palette=['#1f77b4','#ff7f0e'],linewidth=0)    elif tt==3:      umall=sns.scatterplot(x='x',y='y',hue='type',data=plot,s=90,palette=['#1f77b4','#ff7f0e','#2ca02c'],linewidth=0)    elif tt==4:      umall=sns.scatterplot(x='x',y='y',hue='type',data=plot,s=90,palette=['#1f77b4','#ff7f0e','#2ca02c','#d62728'],linewidth=0)    elif tt==5:      umall=sns.scatterplot(x='x',y='y',hue='type',data=plot,s=90,palette=['#1f77b4','#ff7f0e','#2ca02c','#d62728','blue'],linewidth=0)    elif tt==6:      umall=sns.scatterplot(x='x',y='y',hue='type',data=plot,s=90,palette=['#1f77b4','#ff7f0e','#2ca02c','#d62728','blue','green'],linewidth=0)    return umall